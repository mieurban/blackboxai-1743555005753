http.host: "0.0.0.0"
xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]

path.config: /usr/share/logstash/pipeline
path.logs: /var/log/logstash

pipeline.ordered: auto
pipeline.workers: 2
pipeline.batch.size: 125
pipeline.batch.delay: 50

queue.type: persisted
queue.max_bytes: 1gb

log.level: info

config.reload.automatic: true
config.reload.interval: 3s

api.http.host: "0.0.0.0"
api.http.port: 9600

monitoring.enabled: true
monitoring.elasticsearch.hosts: ["http://elasticsearch:9200"]

node.name: logstash-node-1
node.roles: ["logstash"]

# Performance Tuning
pipeline.output.workers: 2
pipeline.aggregation.size: 2048
pipeline.aggregation.max_size: 4096

# Memory Settings
pipeline.java_execution: true
pipeline.plugin_classloaders: true

# Queue Settings
queue.page_capacity: 64mb
queue.max_events: 0
queue.checkpoint.writes: 1024

# Dead Letter Queue
dead_letter_queue.enable: true
dead_letter_queue.max_bytes: 1gb

# Persistent Queue Settings
path.queue: /var/lib/logstash/queue
queue.drain: false

# Pipeline Settings
pipeline.unsafe_shutdown: false
pipeline.ecs_compatibility: v1

# Metrics Settings
monitoring.collection.interval: 10s
monitoring.collection.pipeline.details.enabled: true

# X-Pack Settings
xpack.monitoring.enabled: true
xpack.management.enabled: true
xpack.management.pipeline.id: ["main"]

# SSL/TLS Settings
# ssl.verification_mode: certificate
# ssl.certificate_authority: /path/to/ca.crt
# ssl.certificate: /path/to/client.crt
# ssl.key: /path/to/client.key

# Filter Workers
filter.workers: 2
filter.execution_context: pipeline

# Output Workers
output.workers: 2
output.execution_context: pipeline